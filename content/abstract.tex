\pagenumbering{roman}
\setcounter{page}{1}

\selecthungarian

%----------------------------------------------------------------------------
% Abstract in Hungarian
%----------------------------------------------------------------------------
\chapter*{Kivonat}\addcontentsline{toc}{chapter}{Kivonat}

A nagy teljesítményű párhuzamos számítások elvégzése a mai modern rendszerekben két kategóriára osztódnak szét: közös memória és üzenet küldés alapú megoldásokra. Mind kettő megközelítés célja, hogy az egyes folyamatok képesek legyenek párhuzamosan futni, valamint a másik folyamat által előállított adatok alapján valamiféle új számítási lépést elvégezni. Az 1980-as években a párhuzamos algoritmusok tervezésére és végrehajtására számos módszert dolgoztak ki. A kutatások rámutattak, hogy az algoritmusok egy része nehezen párhuzamosítható üzenet küldés alapú paradigmával, de a közös memóriás rendszerek is számos kihívást tartogattak a szinkronizációk terén. Ezen problémák kiküszöbölésére egy érdekes, un\. koordinációs módszert dolgoztak ki a Yale egyetemen, amely egy olyan közös tárterületet használ, amelynek a módosítására az egyes folyamatok speciális műveleteket hajthattak végre: ennek a gyakorlati megvalósítása volt a Linda nyelv.

A Linda által használt rendszer több előnnyel rendelkezik az elterjedt párhuzamos számítási paradigmákhoz képest. Az egyszerű ennes (tuple) és ennes tér alapú paradigmának köszönhetően az üzenet küldés és az osztott memória alapú megoldások előnyeit is magában hordozza. Az ennes térbe való írás felhasználható üzenetküldésre, míg a közösen elérhető ennes tér maga egy szemi-strukturált osztott memóriát biztosít, ami automatikusan kezeli a kölcsönös kizárást. Ennek megfelelően a Linda modellben megvalósított párhuzamos programok igen egyszerűek, és a sok párhuzamossághoz tartozó kódrészlet helyett a programozó a tényleges feladatra tud koncentrálni. Eredetileg a Linda nyelvet C nyelven a megalkotók által elérhető saját szuperszámítógépük sajátosságainak felhasználásával valósították meg. A megvalósítás alapjául szolgáló ötlet elterjedt az ipari gyakorlatban is annyira, hogy különböző cégek, mint például a Sun Microsystems és az IBM, saját megvalósításokat és specifikációkat alkottak meg, hogy használhatóvá tegyék a Linda nyelvet más rendszerek felhasználói számára is akadémiai és ipari környezetben. Ezek a megvalósítások azonban, vagy valamilyen sajátosságát használták ki egy-egy adott számítógépnek vagy operációs rendszernek, így nem könnyen hordozhatóak, vagy egy nagy méretű virtuális gép absztrakcióját igényelték, ami sok extra erőforrást követel, ami nem a tényleges számításra kerül felhasználásra.

Manapság a párhuzamos számításokra létrehozott számítógépek egy része nem rendelkezik közös memóriával, így többségében MPI-t alkalmaznak a párhuzamos programokhoz, ami az üzenet alapú paradigmát támogatja. Ebben a dolgozatban egy, a mai napig uralkodó párhuzamos számításban használt környezetet, az MPI-t, felhasználó megvalósítást mutatok be, ami modern C++-kódot felhasználva képes a párhuzamosítást hatékonyan megvalósítani számítógép architektúra és operációs rendszer független módon. A módszerrel egyszerűbbé válik a párhuzamos algoritmusok tervezése és megvalósítása. A dolgozatban bemutatok kódrészleteket, amelyek egy párhuzamos programozásba bevezető oktatási anyag részeként szolgálhatnak, és egy olyan programot, amely egy gyakorlati problémára, programkódok párhuzamos fordításra, ad egy egyszerű és érthető megoldást.

\vfill
\selectenglish


%----------------------------------------------------------------------------
% Abstract in English
%----------------------------------------------------------------------------
\chapter*{Abstract}\addcontentsline{toc}{chapter}{Abstract}

High-performance parallel computing in today's modern systems is split into two categories: shared memory and message-passing based solutions. The goal of both approaches is to enable each process to run in parallel and to perform some new computation step based on the data generated by the other process. In the 1980s, a number of methods for designing and implementing parallel algorithms were developed. Research showed that some of the algorithms were difficult to parallelize using a message-passing paradigm, but shared memory systems also presented a number of challenges in terms of synchronization. To overcome these problems, an interesting, so called coordination based, approach was developed at the Yale university using a shared memory space that each process could perform special operations to modify: the practical implementation of this was the Linda language.

The system used by Linda has several advantages over the commonly used parallel computing paradigms. Thanks to its simple tuple and tuple space based paradigm, it also has the advantages of message passing and shared memory solutions. Writing to the tuple space can be used for messaging, while the shared tuple space itself provides a semi-structured shared memory that automatically handles mutual exclusion. Accordingly, the parallel programs implemented in the Linda model are very simple, and instead of many code fragments associated with parallelism, the programmer can concentrate on the actual task at hand. Originally, the Linda language was implemented in C using the features of their own supercomputer available to its creators. The idea behind the implementation has spread into industrial practice, to the point where various companies, such as Sun Microsystems and IBM, have created their own implementations and specifications to make the Linda language usable by users of other systems in academic and industrial environments. These implementations, however, either exploited some peculiarity of a particular computer or operating system, so they are not easily portable, or required the abstraction of a large virtual machine, which requires a lot of extra resources that are not used for the actual computation.

Nowadays, some of the computers designed for parallel computing do not have shared memory, so most of them use MPI for parallel programs, which supports the message-based paradigm. In this paper, I present an implementation using a prevailing parallel computing environment used today, MPI, which can efficiently implement parallelization in a computer architecture and operating system independent manner using modern C++ code. The method is used to simplify the design and implementation of parallel algorithms. In this paper, I present code snippets that can be used as part of an educational material introducing parallel programming, and a program that provides a simple and understandable solution to a practical problem of parallel compilation of program code.

\vfill
\selectthesislanguage

\newcounter{romanPage}
\setcounter{romanPage}{\value{page}}
\stepcounter{romanPage}